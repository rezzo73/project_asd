{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates new directory with con image, t-maps, z-maps, and temporal BOLD 4D images\n",
    "# and design files for OpenAutism (per subject, per task, per run)\n",
    "\n",
    "# FOR FUTURE / PENDING:\n",
    "\n",
    "# once second level is run, must import one con, t-map and z-map per subject (now importing \n",
    "# one per run)\n",
    "\n",
    "# some subjects are in more than one experiment (e.g. SAX_OA_## in both exp1\n",
    "# and exp2). In these cases, only one exp is copied over--the one where the subject has\n",
    "# lower average framewise displacement. DEPENDING ON THE MIXED MODEL WE USE, WE MAY BE ABLE\n",
    "# TO INCLUDE ALL RUNS ACROSS EXPERIMENTS FOR THESE SUBJECTS. BUT DOING THIS FOR NOW AS \n",
    "# PRECAUTIONARY MEASURE.\n",
    "\n",
    "pilot = 1        # 1 = pilot_data / 0 = analysis_data\n",
    "\n",
    "# import modules\n",
    "from glob import glob\n",
    "import re\n",
    "import os.path\n",
    "from itertools import repeat\n",
    "import csv\n",
    "from shutil import copyfile\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subject look up table conversion (IGNORING undescores)\n",
    "def Convert_Subname(Oldname):\n",
    "    tmp_root = '/om/user/rezzo/Subject_Conversion_Table.csv'\n",
    "\n",
    "    with open(tmp_root, \"r\") as tsv:\n",
    "        for line in csv.reader(tsv,  delimiter = \",\"):\n",
    "            if Oldname == line[1].replace(\"_\",\"\"):\n",
    "                Newname = line[0]\n",
    "            else:\n",
    "                continue\n",
    "    return Newname  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_between( s, first, last ):\n",
    "    try:\n",
    "        start = s.index( first ) + len( first )\n",
    "        end = s.index( last, start )\n",
    "        return s[start:end]\n",
    "    except ValueError:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_greater_motion(subject1, subject2):\n",
    "    tmp_root = '/om/user/rezzo/INCLUDE_final.csv'\n",
    "\n",
    "    with open(tmp_root, \"r\") as tsv:\n",
    "        mot1 = []\n",
    "        mot2 = []\n",
    "        subjectarray = [subject1, subject2]\n",
    "        readCSV = csv.reader(tsv, delimiter='\\t')\n",
    "        for line in readCSV:\n",
    "            if subject1 == line[2]:\n",
    "                mot1.append(float(line[9]))\n",
    "                np.array(mot1)\n",
    "            if subject2 == line[2]:\n",
    "                mot2.append(float(line[9]))\n",
    "                np.array(mot2)\n",
    "    if np.mean(mot1) > np.mean(mot2):\n",
    "        return subject1\n",
    "    elif np.mean(mot2) > np.mean(mot1):\n",
    "        return subject2\n",
    "    else:\n",
    "        return random.choice(subjectarray) # temporarily missing data, just choose randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_sub(name):\n",
    "    if name[:4] == 'sub-':\n",
    "        name = name[4:]\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/neuro/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/opt/conda/envs/neuro/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# Looks for subjects that participated in > 1 experiment and identifies which to exclude\n",
    "# based on motion.\n",
    "\n",
    "conversion = '/om/user/rezzo/Subject_Conversion_Table.csv'\n",
    "df = pd.read_csv(conversion, header=None)\n",
    "\n",
    "# make list of all duplicate items\n",
    "a = df[0].tolist()\n",
    "dup_list = [k for k,v in Counter(a).items() if v>1]\n",
    "\n",
    "repeat_subjects = []\n",
    "remove_subjects = []\n",
    "\n",
    "for el in dup_list:\n",
    "    with open(conversion, \"r\") as tsv:\n",
    "        for line in csv.reader(tsv,  delimiter = \",\"):\n",
    "            if el == line[0]:\n",
    "                repeat_subjects.append(line[1])\n",
    "\n",
    "remove_from_list = [repeat_subjects[i:i + 2] for i in range(0, len(repeat_subjects), 2)]\n",
    "\n",
    "for item in remove_from_list:\n",
    "    fixname = identify_greater_motion('sub-'+item[0].replace(\"_\",\"\"), 'sub-'+item[1].replace(\"_\",\"\"))\n",
    "    remove_subjects.append(remove_sub(fixname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run-001\n",
      "run-002\n",
      "run-003\n",
      "run-004\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/om/group/saxelab/OpenAutism/Analysis/first_level_standard_timeseries.py/DOD/sub-SAXDOD025/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-95c6e82584f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m                     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#tomloc/model/\" # f is tasks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0mmm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/model/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                             \u001b[0mrun_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'run'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/om/group/saxelab/OpenAutism/Analysis/first_level_standard_timeseries.py/DOD/sub-SAXDOD025/'"
     ]
    }
   ],
   "source": [
    "root = '/om/group/saxelab/OpenAutism/Analysis/first_level_standard.py/'\n",
    "\n",
    "if pilot == 1:\n",
    "    OA_dir = '/om/user/rezzo/OpenAutism/pilot_data/SUBJECTS/'\n",
    "    remove_subjects = [] # to prevent the filtering out of any subjects in pilot_data\n",
    "else:\n",
    "    OA_dir = '/om/user/rezzo/OpenAutism/analysis_data/SUBJECTS/'\n",
    "\n",
    "all_folders = glob(root+'*/') #obtain all folders within root directory\n",
    "all_subjects = []\n",
    "\n",
    "for folders in range(0, len(all_folders)):\n",
    "    temp = os.listdir(all_folders[folders])\n",
    "    for items in temp:\n",
    "        all_subjects.append(all_folders[folders] +items)\n",
    "        found = items.replace('sub-','')\n",
    "        newname = Convert_Subname(found)\n",
    "\n",
    "        if found in remove_subjects:\n",
    "            print(found+\" is a repeated subject with more motion in this round (skipping)\")\n",
    "        \n",
    "        # create a folder with new name in the OA directory\n",
    "        elif (not os.path.exists(OA_dir+newname)):  \n",
    "            str1=re.split(\"/+\", all_folders[folders])\n",
    "            site = str1[-2]\n",
    "            destroy = 0\n",
    "\n",
    "            proc_streams = ['first_level_standard.py','first_level_aroma.py','first_level_gorgolewski.py']\n",
    "            \n",
    "            for stream in proc_streams:\n",
    "                \n",
    "                if destroy == 1:\n",
    "                    break\n",
    "                    \n",
    "                stream_abrv = find_between(stream, \"level_\", \".py\" )\n",
    "                src_dir = '/om/group/saxelab/OpenAutism/Analysis/'+stream+'/'+site+'/sub-'+found+'/'\n",
    "                \n",
    "                # when raw data available per processing stream, specify below:\n",
    "                design_dir = '/om/group/saxelab/OpenAutism/data/'+site+'/BIDS/'+'sub-'+found+'/func/'\n",
    "                raw_dir = \"/om/group/saxelab/OpenAutism/Analysis/first_level_standard_timeseries.py/\"+site+\"/sub-\"+found+\"/\"\n",
    "\n",
    "                    \n",
    "                os.makedirs(os.path.join(OA_dir+newname,'derivatives',stream_abrv,'first_level_analyses','BOLD_data')) \n",
    "                os.makedirs(os.path.join(OA_dir+newname,'derivatives',stream_abrv,'second_level_analyses','multivariate'))\n",
    "                os.makedirs(os.path.join(OA_dir+newname,'derivatives',stream_abrv,'second_level_analyses','lateralization'))\n",
    "                os.makedirs(os.path.join(OA_dir+newname,'derivatives',stream_abrv,'second_level_analyses','magnitude'))\n",
    "                os.makedirs(os.path.join(OA_dir+newname,'derivatives',stream_abrv,'second_level_analyses','interregional_cor'))\n",
    "                os.makedirs(os.path.join(OA_dir+newname,'derivatives',stream_abrv,'second_level_analyses','temporal_variance'))\n",
    "                os.makedirs(os.path.join(OA_dir+newname,'derivatives',stream_abrv,'second_level_analyses','MISC','individual_roi_masks'))\n",
    "                os.makedirs(os.path.join(OA_dir+newname,'derivatives',stream_abrv,'second_level_analyses','MISC','mean_roi_Temporal_Signal'))\n",
    "\n",
    "\n",
    "                # Copying over: CON, T-MAP, Z-STAT (excluding tomloc data)\n",
    "                all_tasks = glob(src_dir+\"*/\")\n",
    "                all_tasks = [tasks + 'model/' for tasks in all_tasks]\n",
    "\n",
    "                # exclude tomloc data from analysis_data; or if pilot folder only include tomloc\n",
    "                if pilot == 1:\n",
    "                    all_tasks = [ task for task in all_tasks if \"tomloc\" in task ]\n",
    "                else:\n",
    "                    all_tasks = [ task for task in all_tasks if \"tomloc\" not in task ]\n",
    "                \n",
    "                # delete the subject folder in OA dir if no data (e.g. after removing tomloc)\n",
    "                if all_tasks == []:\n",
    "                    destroy = destroy +1\n",
    "                    shutil.rmtree(OA_dir+newname)\n",
    "                    break\n",
    "                         \n",
    "                for tasks in all_tasks:\n",
    "                    str2=re.split(\"/+\", tasks)\n",
    "                    task_name = str2[-3]\n",
    "                    all_runs = glob(tasks+\"*/\")\n",
    "                    counter = 0\n",
    "                    # put all_runs in order\n",
    "                    all_runs = sorted(all_runs)\n",
    "                    for runs in all_runs:   # just in case we end up separating runs within task\n",
    "                        run_num = runs.split('/run')[-1][:-1]\n",
    "                        run_num = 'run-00'+run_num\n",
    "                        print(run_num)\n",
    "                        prefixed1 = [filename for filename in os.listdir(runs) if (filename.startswith(\"con_1_\") and filename.endswith(\"_tstat.nii.gz\"))]\n",
    "                        #print(runs+prefixed1[0])\n",
    "                        copyfile(runs+prefixed1[0], OA_dir+newname+'/derivatives/'+stream_abrv+'/first_level_analyses/tstat1_'+task_name+'_'+run_num+'.nii.gz')\n",
    "                        prefixed2 = [filename for filename in os.listdir(runs) if (filename.startswith(\"con_1_\") and filename.endswith(\"_cope.nii.gz\"))]\n",
    "                        copyfile(runs+prefixed2[0], OA_dir+newname+'/derivatives/'+stream_abrv+'/first_level_analyses/cope1_'+task_name+'_'+run_num+'.nii.gz')\n",
    "                        prefixed3 = [filename for filename in os.listdir(runs) if (filename.startswith(\"con_1_\") and filename.endswith(\"_zstat.nii.gz\"))]\n",
    "                        copyfile(runs+prefixed3[0], OA_dir+newname+'/derivatives/'+stream_abrv+'/first_level_analyses/zstat1_'+task_name+'_'+run_num+'.nii.gz')\n",
    "\n",
    "\n",
    "                    # Copying over: TEMPORAL DATA AND DESIGN FILE (analysis_data EXCLUDES TOMLOC DATA)\n",
    "                    results = []\n",
    "                        \n",
    "                    for f in os.listdir(raw_dir): #tomloc/model/\" # f is tasks\n",
    "                        for mm in os.listdir(raw_dir+f+'/model/'):\n",
    "                            run_num = mm.split('run')[1]\n",
    "                            run_num = 'run-00'+run_num\n",
    "                            for ll in os.listdir(raw_dir+f+'/model/'+mm):\n",
    "                                if re.search(r'res4d.nii.gz', ll):\n",
    "                                    results.append(f+'/'+ll)\n",
    "                                    #print(f[-1])\n",
    "                                    copyfile(raw_dir+f+'/model/'+mm+'/'+ll, OA_dir+newname+'/derivatives/'+stream_abrv+'/first_level_analyses/BOLD_data/temporaldata_'+f+'_'+run_num+'.nii.gz')\n",
    "\n",
    "                    design = []  \n",
    "                    for f in os.listdir(design_dir):\n",
    "                        if (re.search(r'.tsv', f)):\n",
    "                            design.append(f)\n",
    "\n",
    "                    if pilot == 1:\n",
    "                        design = [ N for N in design if \"tomloc\" in N ]\n",
    "                    else:\n",
    "                        design = [ N for N in design if \"tomloc\" not in N ]\n",
    "                    \n",
    "                    for elements in range(0, len(design)):   \n",
    "                        abbrev = find_between( design[elements], \"task-\", \"_events\" )\n",
    "                        copyfile(design_dir+design[elements], OA_dir+newname+'/derivatives/'+stream_abrv+'/first_level_analyses/BOLD_data/design_'+abbrev+'.tsv') \n",
    "                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
